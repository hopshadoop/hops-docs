===========================
What is Hopsworks?
===========================

Hopsworks is a full-stack platform for scale-out data science, with support for both GPUs and Big Data, in a familiar development environment. Hopsworks unique features are:

* User-friendly UI for Developing with the latest open-source platforms for Data Science (Jupyter, Conda, etc),
* Github-like Projects to manage teams/products/workflows/data,
* Managed GPUs as a Resources - scale out Deep Learning training and hyperparameter optimization,
* World's fastest, most-scalable distributed hierarchical filesystem.
* Unified REST API for the whole Hopsworks Platform,
* TLS Certificate based security model with extensive auditing and data provenance capabilities,
* End-to-end support for Python-based Deep Learning workflows with: a Feature Store, Data and Model Validation, Model Serving on Kubernetes, workflow orchestration in Airflow.

Hopsworks supports the following open-source platforms for Data Science:

* Development: Jupyter, plugin to IDEs (vi the REST API), Conda/Pip;
* Machine Learning: TensorFlow, Keras, PyTorch, ScikitLearn;  
* Data Analytics/BI: Spark, Hive;
* Stream Processing: Spark-Streaming, Flink, Kafka;
* Model Serving: Kubernetes/Docker.


Projects
=====================  


.. figure:: ../imgs/projects/hopsworks-projects-medium.png
  :alt: Projects in Hopsworks
  :scale: 60
  :figclass: align-center

  Just like Github is made up of repositories, Hopsworks is made up of lots of *Projects*. A Project is, in turn, a collection of users, data assets, and programs (code). 


.. figure:: ../imgs/projects/hopsworks-projects-detailed.png
  :alt: Detailed view of Projects in Hopsworks
  :scale: 60
  :figclass: align-center

  Projects also have quotas associated with them - CPU/GPU and how much data they can store.
  


  
Small-Scale Machine Learning Workflows
========================



Large-Scale Machine Learning Workflows
========================
