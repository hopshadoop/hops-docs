=============
Version 1.4.0
=============

Provenance
==========

When upgrading to version 1.4.0 you can enable large xattr. 
By default xattr max size is 13500(13KB) and 255 for its name. You can increase this value to 3442755(3MB) by changing the hops config. 
Another limitation is the number of different xattrs that can be attached to each file. By default the number is 32. This can also be increased to 127 by changing the hops config.

If you want to modify the above values in a cluster definition add:
.. code-block:: yaml
    hops:
        xattrs:
            max-xattrs-per-inode: 127
            max-xattr-size: 3442755

If you want to modify these values on a live cluster, you can do this in the `/srv/hops/hadoop/etc/hadoop/hdfs-site.xml`. Modify the following properties:

.. code-block:: yaml
    <property>
        <name>dfs.namenode.xattrs.enabled</name>
        <value>...</value>
        <description>
            Whether support for extended attributes is enabled on the NameNode.
        </description>
    </property>
    <property>
        <name>dfs.namenode.fs-limits.max-xattrs-per-inode</name>
        <value>...</value>
        <description>
            Maximum number of extended attributes per inode. The maximum allowed number is 127 extended attributes per inode.
        </description>
    </property>
    <property>
        <name>dfs.namenode.fs-limits.max-xattr-size</name>
        <value>...</value>
        <description>
            The maximum combined size of the name and value of an extended attribute in bytes. It should be larger than 0 and less than or equal to the maximum size (hard limit), which is 3442755. By default, this limit is 1039755 bytes, where the name can take up to 255 bytes, and the value size can take up to 1039500 bytes.
        </description>
    </property>

Since these xattr are used for attaching provenance information, as a rough estimate(with max name size and other details) you can use:
Featuregroups:
* 67755 - max 1000 features per featuregroup
* 634755 - max 10000 features per featuregroup
* 1039755 - max 16000 features per featuregroup
* 34427552 - max 54000 features per featuregroup

Training datasets:
* 67755 - max 1000 features coming from about 10 featuregroups
* 634755 - max 10000 features coming from about 20 featuregroups
* 1039755 - max 16000 features coming from about 20 featuregroups
* 34427552 - max 54000 features coming from about 20 featuregroups

Python environment migration
============================

Hopsworks back end mechanism for managing projects' Python environment is now more scalable and robust by moving to
Docker based Anaconda environments. That means Python environments of existing projects will defaut back to the base
Python environment provided by Hopsworks, so all additional Python libraries that were installed will be lost.

Users can find a YAML file that contains the exported Anaconda environment of the project including any
user-installed libraries. This file can be found in the `Resources` dataset with a name `python_env_<project>.yml`
where <project> is the project name. Users can use this YAML file to refer to previously installed Python libraries
and then manually install them through the UI or the REST API. Importing the exported environment is discouraged as
the base environment has been modified from the previous version and certain libraries such as TensorFlow will
malfunction.


TensorFlow 1.x dropped
======================

As of this Hopsworks version only TensorFlow 2.x is supported. TensorFlow 1.x is not included in a project's default
Python environment.